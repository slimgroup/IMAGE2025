---
title: "Rock Physics-Sensitivity-Aware Digital Shadow for CO~2~ Storage Monitoring"
#author:
bibliography: abstract.bib
crossref:
  fig-prefix: figure
  eq-prefix: equation
filters:
    - SLIM
format:
  html:
    page-layout: full
    sidebar: false
    lightbox: true
    crossrefs-hover: true
  pdf:
    template: IMAGEAbstractTemplate.latex
    csl: apa.csl
    keep-tex: true
abstract: Geological Carbon Storage (GCS) requires precise CO~2~ plume monitoring to track potential leakage pathways, but time-lapse seismic imaging alone is insufficient. A recently developed Digital Shadows (DS) enhances forecasting using machine learning and Bayesian inference, yet their accuracy depends on assumed rock physics models, the mismatch of which can lead to unreliable predictions. Augmenting DS training with multiple rock physics models mitigates errors but averages over uncertainties, obscuring their sources. To overcome this, we introduce context-aware sensitivity analysis inspired by Amortized Bayesian Inference (ABI), allowing DS to learn explicit dependencies between seismic data, CO~2~ saturation, and rock physics models. This enables real-time adaptation to different rock physics assumptions at inference time rather than relying on costly retraining, thereby enhancing interpretability and decision-making for safer, more reliable CO~2~ storage.
---

::: {.hidden}

\newcommand{\argmin}{\mathop{\mathrm{argmin}\,}\limits}
\newcommand{\argmax}{\mathop{\mathrm{argmax}\,}\limits}
$$
\def\textsc#1{\dosc#1\csod} 
\def\dosc#1#2\csod{{\rm #1{\small #2}}} 
$$

:::

# Introduction

The critical challenge of reducing global greenhouse gas emissions to mitigate anthropogenic climate change calls for the need for engineered geological carbon storage (GCS). Since the industrial revolution, the extensive combustion of fossil fuels has significantly increased atmospheric CO2 ~ concentrations, contributing to global warming [@ringrose2020store]. Despite growing efforts to transition towards renewable energy sources, the current global energy system remains heavily reliant on fossil fuels, particularly in power generation, manufacturing, and transportation [@IEA_2016]. Given the intermittency of renewable energy and the scale of emissions reduction required, an integrated approach combining multiple mitigation strategies is necessary. GCS plays a vital role in this transition by providing a means to decarbonize existing energy infrastructure and industrial processes while enabling negative emissions when coupled with bioenergy [@ringrose2020store;@masson2018global]. Furthermore, GCS facilitates a more cost-effective and timely reduction in emissions compared to relying solely on renewable energy expansion [@iiasa14349; @ringrose2020store; @IEA_2016]. However, to align with the targets set by the Paris Agreement [@COP21_2015], the deployment of GCS must be significantly scaled up, necessitating advancements in geological CO~2~ storage technologies and the expansion of large-scale storage facilities [@GCCSI_2019]. This necessitates precise monitoring of subsurface CO~2~ dynamics to ensure that CO~2~ plumes remain confined within the intended storage formations, preventing migration into adjacent strata [@ringrose2023storage] and ultimately avoiding release into the atmosphere. While time-lapse seismic imaging is essential for monitoring CO~2~ plume migration, it often lacks the resolution to fully characterize the complexities of multi-phase subsurface flow.

Digital Shadows (DS), powered by machine learning-driven data assimilation techniques such as nonlinear Bayesian filtering and generative AI [@spantini2022coupling; @gahlot2024uads], offer a high-fidelity approach to characterize subsurface CO~2~ flow [@herrmann2023president; @gahlot2023NIPSWSifp; @gahlot2024uads]. By incorporating uncertainty in reservoir properties such as permeability, DS provides uncertainty-aware CO~2~ migration forecasts, including predictions of plume pressure and saturation, thereby reducing risks in geological carbon storage (GCS) projects by enabling decision-making.

However, the accuracy of these forecasts depends on assumptions regarding reservoir properties, rock physics models, and initial conditions. If these assumptions are inaccurate, predictions can become unreliable, compromising GCS safety. @gahlot2025erd showed that when a DS is trained assuming a particular rock physics model and evaluated with a different rock physics, it outputs an incorrect plume prediction. To address this challenge, @gahlot2025erd proposed augmenting the forecast ensemble used for training neural networks in the data assimilation process. By incorporating multiple rock physics models ranging from patchy to uniform saturation, their approach mitigates the impact of model misspecification and enhances predictive accuracy in key scenarios.

While this approach marginalizes over plausible rock physics models, it loses its capability for explicit reasoning. By producing a marginal posterior, the plume predictions become averaged across all possible rock physics models, resulting in broader uncertainty bounds, which can obscure the true source of uncertainty and complicate decision-making. Without an explicit treatment of rock physics variability, it becomes unclear whether uncertainties arise due to seismic noise, uncertain permeability, or incorrect assumptions about the rock physics model itself. This lack of interpretability can reduce confidence in monitoring and forecasting CO~2~ plume behavior in geological storage settings.

To circumvent this, we need a framework that enables sensitivity analysis of the Digital Shadow over a range of rock physics models. However, training a separate network for each rock physics model is infeasible, as retraining is costly and data-intensive. Traditionally, sensitivity analyses have relied on computationally expensive refitting procedures, where a new model is trained for each specific configuration, limiting scalability and generalization in real-world monitoring scenarios. @elsemuller2024sensitivityaware demonstrates that Amortized Bayesian Inference (ABI) [@radev2020bayesflow] provides a principled way to assess the sensitivity of model predictions without requiring separate network training for each context. ABI not only enables rapid inference across unseen datasets but also facilitates systematic uncertainty quantification by incorporating context variables into the neural network. These context variables allow the model to learn a context-aware conditional posterior, thereby capturing the dependence of inferred parameters on different forward model assumptions. This allows for a faster and more structured approach to sensitivity analysis, where the impact of different rock physics models, in the case of DS, can be assessed directly at inference time rather than through costly retraining.

Motivated by this, we extend the approach in @gahlot2025erd by incorporating explicit rock physics sensitivity analysis within the DS framework. Instead of training separate models for different rock physics configurations, we introduce context variables representing the rock physics model into the training process. This allows the network to learn an explicit mapping between seismic data, CO~2~ saturation, and the rock physics model, thereby improving robustness, interpretability, and generalization. By including rock physics as a context variable, we perturb seismic images corresponding to CO~2~ saturation forecasts in the training ensembles in a structured manner. This ensures that the DS can dynamically adapt to different rock physics models during inference rather than producing a posterior smeared over all possible models. As a result, our approach enables not only uncertainty quantification over CO~2~ plume forecasts but also a direct assessment of how different rock physics assumptions affect CO~2~ plume prediction results, enhancing decision-making for geological carbon storage monitoring.

# Methodology

Building upon the uncertainty-aware Digital Shadow (DS) framework introduced in [@gahlot2024uads], we develop a Bayesian inference-driven approach for tracking CO~2~ plume evolution in geological storage reservoirs. The temporal dynamics of CO~2~ saturation and pressure perturbations are modeled as:

$$
\begin{aligned}
\mathbf{x}_k & = \mathcal{M}_k\bigl(\mathbf{x}_{k-1}, \boldsymbol{\kappa}_k\bigr), \ \boldsymbol{\kappa}_k \sim p(\boldsymbol{\kappa}) \quad \text{for}\quad k=1, \dots, K.
\end{aligned}
$$ {#eq-dynamics}

where $\mathbf{x}_k$ represents the CO~2~ saturation and pressure perturbations at time step $k$, governed by the multi-phase fluid flow operator $\mathcal{M}_k$. The permeability field $\boldsymbol{\kappa}$, which plays a crucial role in CO~2~ migration and storage efficiency, is inherently uncertain due to subsurface heterogeneity [@ringrose2020store]. To account for this uncertainty, we model permeability as a random variable drawn from a probability distribution $p(\boldsymbol{\kappa})$. This ensures that the simulation framework can generate a diverse set of plausible CO~2~ migration scenarios, capturing the inherent variability of geological formations.

While fluid flow simulations provide physically consistent plume dynamics, they remain impractical without observational constraints due to the inherent stochasticity of permeability and the uncertainty in rock physics models. Time-lapse seismic imaging [@lumley20104d] serves as a key monitoring tool, providing indirect observations of CO~2~ plume migration. The corresponding observation model is defined as:

$$
\mathbf{y}_k = \mathcal{H}_k(\mathbf{x}_k;\mathcal{R}_k) + \boldsymbol{\epsilon}_k, \quad \boldsymbol{\epsilon}_k \sim p(\boldsymbol{\epsilon}), \quad \mathcal{R}_k \sim p(\mathcal{R}) \quad \text{for}\quad k=1, \dots, K
$$ {#eq-obs}

where $\mathbf{y}_k$ represents the seismic data recorded at time $t_k$, $\mathcal{H}_k$ is the seismic forward operator, and $\boldsymbol{\epsilon}_k$ is the colored Gaussian noise added to the seismic shot records before reverse-time migration and accounts for uncertainties in wave propagation and measurement errors. The term $\mathcal{R}_k$ corresponds to the rock physics transformation, which links fluid flow properties to seismic attributes. To account for uncertainty in rock physics, we sample $\mathcal{R}_k$ from a family of Brie Saturation models, with the exponent $e$ uniformly drawn from the range $e \sim \mathcal{U}(1,10)$. This exponent brings a context-aware data augmentation strategy that ensures that seismic images reflect a spectrum of plausible rock physics assumptions. To infer the posterior distribution of CO~2~ plume states from seismic data and the context, we employ Conditional Normalizing Flows (CNFs, [@nf; @gahlot2024uads]) within a simulation-based inference framework utilizing the training pairs of CO~2~ plume states and corresponding seismic images by varying both permeability and rock physics models (cf. equations [-@eq-dynamics] and [-@eq-obs]). This results in a richly augmented training set, where multiple seismic realizations are generated along with their contexts for each plume sample. The CNF approximates the posterior distribution $p(\mathbf{x}_k | \mathbf{y}_k)$, allowing for real-time Bayesian updates as new seismic data become available. This approach marries sequential Bayesian inference with neural posterior density estimation, leveraging deep generative models for rock physics context-aware CO~2~ plume forecasting.

# Synthetic Case Study

To assess the proposed methodology, we utilize a synthetic 2D Earth model derived from the Compass model [@BG], which is representative of geological formations in the North Sea region. A subset of this model, containing key subsurface structures suitable for CO~2~ injection, is selected and discretized into a computational grid of $512 \times 256$ with a spatial resolution of $6.25 \ \mathrm{m}$. The initialization of the DS requires an ensemble of potential CO~2~ plume scenarios, which depend on the inherent uncertainty in the permeability distribution of the storage reservoir. To account for this variability, we establish a probabilistic baseline velocity model, inferred through full-waveform inversion [@yin2024wise] under the assumption of a baseline seismic survey conducted before CO~2~ injection. The resulting samples of the velocity distribution are then converted into permeability samples using an empirical transformation elucidated in @gahlot2024uads.

## Multi-Phase Flow Simulations

Flow simulations are conducted using the open-source tool JutulDarcy JutulDarcy.jl [@jutuldarcy]. In the initial setup, the reservoir is filled with brine, and supercritical CO~2~ is injected at a constant rate of $0.0500 \ \mathrm{m^3/s}$ for 1920 days. The injection occurs at an approximate depth of $1200 \ \mathrm{m}$. The simulation is performed over four time-lapse intervals, denoted as $t_k$, generating predicted CO~2~ saturation values for each of the $N=128$ ensemble members at every timestep.

## Context-Augmented Seismic Simulations

The outputs from the 128 flow simulations are translated into changes in subsurface acoustic properties through the application of 6 different contexts (exponent of the Brie Saturation model [@avseth2010quantitative]). This approach effectively augments the dataset by a factor of six, generating distinct acoustic changes for each seismic simulation. The seismic surveys are conducted using 8 receivers and 200 sources, with a dominant frequency of 15 Hz and a recording duration of 1.8 seconds. To simulate real-world conditions, 28 dB SNR colored Gaussian noise is added to the shot records. Nonlinear wave simulations and imaging are performed using the open-source package [JUDI.jl](https://github.com/slimgroup/JUDI.jl)[@witte2018alf; @JUDI], after incorporating various rock physics models.

## CNF Training

The training dataset consists of $768$ ensemble members, each consisting of a forecasted CO~2~ plume, its corresponding seismic observations, and the context. A Conditional Normalizing Flow (CNF) is trained using the open-source package InvertibleNetworks.jl [@orozco2023invertiblenetworks]. To avoid retraining neural approximators for each context, we incorporate the context $C$ into the networkâ€™s amortization framework. This context $C$ corresponds to an embedding of the Brie saturation exponent $e$. We integrate this context into the standard negative log-posterior objective of the CNF, represented as, $\mathbb{E}_{\mathbf{x} \sim q_{\phi}(\mathbf{x} | \mathbf{y}, C)} \left[ - \log q_{\phi}(\mathbf{x} | \mathbf{y}, C) \right]$, and is evaluated using the samples of the approximate surrogate distribution $q_{\phi}$. To achieve the required amortization over a set of context variables C, which is obtained from the Brie exponent $e \sim \mathcal{U}(1,10)$, we minimize the context-aware (CA) loss, $\mathbb{E}_{e \sim P(e)} \left[ \mathbb{E}_{(\mathbf{x} \sim q_{\phi}(\mathbf{x} | \mathbf{y}, C)} \left[ - \log q_{\phi}(\mathbf{x} | \mathbf{y}, C) \right] \right]$, where the outer expectation is evaluated using the samples of $e$. Following @gahlot2024uads, all of these boils down to training a CNF where the network parameters $\boldsymbol{\phi}$ are optimized by minimizing the following objective function over 300 epochs, utilizing the $\textsc{ADAM}$ optimizer [@Kingma2014AdamAM]:
$$
\widehat{\boldsymbol{\phi}} = \argmin_{\boldsymbol{\phi}} \frac{1}{M}\sum_{m=1}^M \Biggl(\frac{\Big\|f_{\boldsymbol{\phi}}(\mathbf{x}^{(m)};(\mathbf{y}^{(m)},C^{(m)}))\Big\|_2^2}{2} - \log\Bigl |\det\Bigl(\mathbf{J}^{(m)}_{f_{\boldsymbol{\phi}}}\Bigr)\Bigr |\Biggr).
$$ {#eq-loss-CNF}

where $\mathbf{J}$ is the Jacobian of the network $f_{\theta}$ with respect to its input, and $M$ is the number of training samples. For further details, we refer to [@gahlot2024uads].

# Results

The performance of our enhanced Digital Shadow framework, incorporating rock physics, is shown in @fig-sup. The top row in each figure presents, from left to right, the ground truth (GT) CO~2~ plume, the conditional mean of the posterior samples, and a sample from the posterior. The bottom row displays, from left to right, the seismic observation, the error between the conditional mean and the ground truth, and the uncertainty. As shown in @fig-naug-idy, the non-augmented DS performs well when the seismic observation matches the correct rock physics model, with the conditional mean closely approximating the GT. However, performance degrades when the seismic observation is based on a different, unknown rock physics model, as seen in @fig-naug-oody, where the conditional mean deviates from the GT, leading to increased error and uncertainty. Augmenting the ensemble improves generalization when seismic observations are based on an unknown rock physics model, as demonstrated in @fig-aug-oody. In this case, the conditional mean is closer to the GT, and both error and uncertainty are reduced compared to the non-augmented approach.

::: {#fig-sup layout-nrow=3}


Caption

:::

# Conclusions

This study demonstrates that uncertainties in permeability and rock physics models can significantly impact the accuracy of CO~2~ plume predictions. By augmenting the forecast ensemble, DS is able to account for unknown rock physics models (at least within the family of Brie saturation models where the exponent $e$ is not specified) and fluid-flow properties. The enriched dataset improves the fidelity of CO~2~ plume forecasts, thereby enhancing the reliability of GCS monitoring.

# Acknowledgement
This research was carried out with the support of Georgia Research Alliance, partners of the ML4Seismic Center and in part by the US National Science Foundation grant OAC 2203821. The overall readability is enhanced using ChatGPT 4. 

# References {.unnumbered}

::: {#refs}
:::